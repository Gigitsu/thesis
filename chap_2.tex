In questo capitolo introduciamo notazioni formali e diamo una breve spiegazione del funzionamento delle reti neurali e degli strumenti utilizzati.

\section{Il Tempo}

Le RNN non sono limitate a sequenze indicizzate in maniera temporale.
Sono state usate con successo anche per seqenze di dati non temporali, come ad esempio i dati genetici.
In ongi caso, la computazione procede nel tempo e molte importanti applicazioni hanno un aspetto temporale esplicito o implicito.

Nonostante, in questa tesi, ci riferiremo al tempo i metodi descritti sono applicabili ad una famiglia pi\`u ampia di compiti.
Parlando di tempo ci riferiamo ad un campione $x^{(t)}$ in input e ad un valore atteso $y^{(t)}$ in output che sono generati in \emph{sequenze di fasi temporali} discrete indicate da $t$
La nostra sequenza pu\`o essere formata da un numero finito di campioni o da un numero infinito ma numerabile di campioni.
Se abbiamo a che fare con un numero finito di campioni allora possiamo indicare con $T$ il massimo indice temporale.
Quindi una sequenza di valori di input consecutivi pu\`o essere scritta come $(x^{(1)}, x^{(2)}, \dots, x^{(T)})$ mentre gli output come $(y^{(1)}, y^{(2)}, \dots, y^{(T)})$.
Questi valori possono essere dei campioni, presi ad intervalli regolari di tempo, di un processo reale continuo come ad esempio i fotogrammi che compongono un video.
Gli intervalli di tempo possono anche essere dei semplici valori ordinali senza una durata esatta.
\`E il caso, ad esempio, delle sequenze genetiche che hanno un ordine ma non un ordine temporale o ancora del linguaggio naturale dove le parole hanno un ordine logico ben preciso che, tuttavia, non corrisponde ad intervalli di temporali ben defniti.
Ad esempio nella frase ``\emph{Lisa suona il sassofono}'' abbiamo che $x^{(1)}$ = Lisa, $x^{(2)}$ = suona, ecc. Ciascuna parola corrisponde ad intervalli di tempo che non sono costanti, ``\emph{il}'' e ``\emph{sassofono}'' hanno bisogno di tempi diversi per essere pronunciati.

\section{Reti Neurali}
Le reti neurali sono modelli computazionali ispirati dalla biologia del sistema nervoso centrale.
Generalmente una rete neurale \`e formata da un insieme di \emph{neuroni artificiali}, comunemente chiamati \emph{nodi} o \emph{unit\`a}, collegati da un insieme di archi diretti che, intuitivamente, rappresentano le \emph{sinapsi} di una rete neurale biologica.
Associato ad ogni neurone $j$ vi \`e una funzione di attivazione $l_j$, chiamata anche funzione di collegamento (o funzione link).
In questa tesi user\`o la notazione ``$l_j$'' invece di ``$h_j$'' (notazione usata in altri documenti) per distinguere la funzione di attivazione $l_j$ dal valore dei nodi nascosti in una rete, che vengono comunemente indicati con \textbf{h} nella letteratura delle RNN.

Associato ad ogni arco dal nodo $j^{'}$ al nodo $j$ vi \`e un peso $w_{jj^{'}}$. Seguento la convenzione adottata in molti altri documenti che trattano reti neurali, indicheremo i neuroni con $j$ e $j^{'}$ mentre, con $w_{jj^{'}}$, indicheremo il peso corrispondente all'arco diretto che parte dal nodo $j^{'}$ e arriva al nodo $j$.
\`E importante notare che in altri documenti e libri, come ad esempio su Wikipedia, gli indici dei pesi sono invertiti e che $w_{j^{'}j} \neq w_{jj^{'}}$ indica il peso sull'arco diretto dal nodo $j^{'}$ al nodo $j$.

Il valore $v_j$ di ciascun neurone $j$ \`e calcolato applicando la sua funzione di attivazione ad una somma pesata dei suoi valori di input (\mytodo{Aggiungere un'immagine!}): %TODO pensare ad un titolo piu' appropiato
\begin{equation*}
  v_j = l_j\left( \sum_{j^{'}} w_{jj^{'}} \cdot v_{j^{'}} \right)
\end{equation*}
Per comodit\`a, ci riferiremo alla somma pesata all'interno delle parentesi come l'\emph{attivazione in arrivo} e la indicheremo con $a_j$. Rappresentiamo l'intero processo in figura disegnando i neuromi coe dei cerchi mentre gli archi come delle frecce che li collegano.
Quando possibile, verr\`a utilizato un simbolo per indicare l'esatta funzione di attivazione utilizzata, ad esempio $\sigma$ per la fnzione sigmoide.

Scelte abbastanza comuni per la funzione di attivazione includono la funzione sigmoide $\sigma(z) = 1/(1+e^{-z})$ e la funzione \emph(tanh) $\phi(z)=(e^z-e^{-z})/(e^z+e^{-z})$ che \`e diventata molto comune nelle reti neurali di tipo \emph{feedforward} ma \`e stata utilizzata anche in reti neurali ricorrenti~\cite{Sutskever:2011}.
Un'altra funzione di attivazione che \`e diventata lo stato dell'arte nella ricerca di deep learning \`e la funzione ReLU (\emph{rectified linear unit}) $l_j(z)=\operatorname{max}(0, z)$.
Questa funzione ha dimostrato di poter migliorare le prestazioni di molte reti neurali in una grande variet\`a di applicazioni, che spaziano dal riconoscimento vocale al riconoscimento di oggetti, ed \`e stata utilizzata anche in reti neurali ricorrenti~\cite{Bengio:2013}.

La funzione di attivazione da applicare sui nodi di output dipende dall'applicazione.
Per una classificazione a pi\`u classi, applichiamo al livello di output una funzione non lineare softmax.
La funzione softmax calcola l'output come:
\begin{equation*}
  \hat{y_k} = \frac{e^{a_k}}{\sum_{k^{'}=1}^{K} e^{a_{k^{'}}}}
\end{equation*}
dove $K$ \`e il numero totale di possibili output (classi). Il denominatore \`e una funzione di normalizzazione che consiste nella somma di funzioni esponenziali dei valori dati in output da tutti i nodi e serve per assicrarsi che l'output totale sommi ad 1.
Nel caso di regressioni invece viene comunemente utilizzata una funzione lineare come output.
Dato che nella maggioranza dei casi le reti neurali, specialmente quelle ricorrenti, vengono utilizzate per applicazioni che coinvolgono la classificazione, durante questa tesi, a meno che diversamente specificato, daremo per scontato l'uso della funzioen softmax come output.

\section{Reti Neurali Feedforward}
Con un modello computazionale a rete neurali, \`e necessario determinare l'ordine con cui la computazione dovrebbe procedere.
I nodi dovrebbero essere calcolati uno alla volta e poi aggiornati, oppure i valori di tutti i nodi dovrebbero essere calcolati iniseme per poi applicare tutti gli aggiornamenti simultaneamente?
Le \emph{reti neurali feedforward} (\mytodo{aggiungere figura ffnn}) sono una classe ristretta di reti neurali che affrontano questo prolema proibnedo i cicli dal grafo delle connessioni neurali.
In questo modo tutti i nodi possono essere disposti in livelli.
I valori in output di ciascun livello possono essere calcolati solo a partire dai valori di output dei livelli precedenti.

L'input $x$ viene dato in pasto ad una rete neurale feedforward impostando i valori dei nodi del livello pi\`u in basso.
I valori dei nodi di ciascuno dei livelli superiori non potranno essere calcolati finch\`e non saranno disponibili i valori in output $\hat{y}$ dei livelli inferiori.
Queste tipologie di reti sono usate di frequente per applicazioni di apprendimento supervisionato come classificazione e regressione.
L'apprendimento \`e ottenuto aggiornando iterativamente i pesi dei singoli archi in modo da minimizzare una funzione di perdita, $\mathcal{L}(\hat{y},y)$, che penalizza la distanza fra l'output desiderato $y$ e l'output predetto $\hat{y}$ tramite tecniche di ottimizzazione.
Nonostante l'algoritmo di ottimizzazione esatto \`e un noto problema NP-Completo, una grande quantit\`a di euristiche pre addestramento e avanzate tecniche di ottimizzazione hanno condotto ad un impressionante numero di successi empirici su molte applicazioni di apprendimento supervisionato.

L'algoritmo utilizzato con maggiore successo per addestrare una rete neurale \`e l'algoritmo di backpropagation, introdotto da Rumelhart et al. nel 1985~\cite{Rumelhart:1985}.
Questo algoritmo usa la regola della catena per calcolare la derivata di una funzione di perdita $\mathcal{L}$ rispetto ciascun parametro nella rete.
I pesi sui singoli archi vengono poi tramite la discesa dei gradienti.
Dato che la superficie di perdita non \`e convessa non vi \`e alcuna garanzia che l'algoritmo di backpropagation riesca a trovare un minimo globale.
Ci\`o nonostante, nella pratica, reti addestrate in questo modo hanno ottenuto notevoli successi.

Tuttavia le reti feedforward sono limitate.
Dopo che ciascun campione \`e stato processato l'intero stato della rete viene perso.
Se i campioni sono indipendenti gli uni dagli altri questo non presenta assolutamente un problema.
Ma se i dati sono in una relazione temporale, questo non \`e accettabile.
I fotogrammi di un video o le parole di una frase rappresentano situazioni in cui l'assunzione di indipendenza fallisce.

\section{Reti Neurali Ricorrenti}
Le \emph{reti neurali ricorrenti} costituiscono un sovrainsieme proprio delle reti neurali feedforward che, a differenza di quest'ultime, includono degli archi ricorrenti.
Questi archi ricorrenti si estendono su intervalli temporali adiacenti e introducono il concetto di tempo nel modello.
Mentre le RNN possono non contenere cicli tra gli archi convenzionali, gli archi ricorrenti possono formare cicli.
Al tempo $t$, i nodi che ricevono un input da un arco ricorrente, ricevono un \emph{input di attivazione} sia dal campione corrente $x^({t})$ che dai nodi nascosti $h^{(t-1)}$ del precedente stato della rete.
L'output $\hat(y^{(t)})$ \`e poi calcolato in base allo stato nascosto $h^{(t)}$ del tempo $t$.
Quindi, l'input $x^({t})$ al tempo $t-1$ pu\`o influenzare l'output $\hat(y^{(t)})$ al tempo $t$ proprio grazie a queste connessioni ricorrenti.

Le seguenti due equazioni, mostrano i calcoli necessari per eseguire, per ogni fase temporale, il passaggio in avanti dei dati di una semplice rete neurale ricorrente:
\begin{equation*}
  h^{(t)} = \sigma(W_{hx}x + W_{hh}h^{(t-1)} + b_h)
  \hat{y^{(t)}} = \operatorname{W_{yh}h^{(t)} + b_y}
\end{equation*}

dove $W_{hx}$ \`e la matrice dei pesi tra il livello di input e il livelo nascosto mentre $W_{hh}$ \`e la matrice dei pesi ricorrenti fra i livelli nascosti di due fasi temporali adiacenti.
I vettori $b_h$ e $b_y$ rappresentano uno scostamento (bias) che permettono a ciascun nodo di apprendere un offset.

I modelli discussi in questa tesi consistono in reti con livelli nascosti ricorrenti.
Tuttavia, sono stati proposti modelli, come la rete di Jordan, che ammettono la presenza di connessioni tra gli output della rete in uno stato e il livello nascosto della rete nello stato successivo.

Una semplice rete neurale \`e mostrata in \mytodo{aggiungere immagine rnn}.
La dinamica di questa rete attravesso pi\`u fasi temporali pu\`o essere visualizzata \emph{dispiegando} la rete (\mytodo{aggiungere immagine}).
Con questa visualizzazione, il modello pu\`o essere interpretata come una rete non ciclica, ma piuttosto come una rete con un livello per intervallo di tempo a dei pesi condivisi tra gli intervalli temporali.
Diventa quindi chiaro come una rete dispiegata in questo modo pu\`o essere addestrata attraverso pi\`u fasi temporali usando l'algoritmo di backpropagation.
Questo algoritmo viene chiamato \emph{backpropagation through time} (BPTT, backpropagation attraverso il tempo), ed \`e stata introdotta nel 1990~\cite{Werbos:1990}

\subsection{Addestramento}
L'apprendimento con le reti neurali ricorrenti \`e stato a lungo visto come qualcosa di difficile.
Cos\`i come per tutte le reti neurali, l'ottimizzazione della funzione di perdita \`e un problema NP-Completo.
Ma l'apprendimento con le reti ricorrenti pu\`o essere reso ancora pi\`u complesso a causa della difficolt\`a nell'apprendere delle dipendenze a lungo raggio.
Il noto problema della \emph{scomparsa} ed \emph{esplosione} dei gradienti si verifica quando l'errore viene propagato attraverso molte fasi temporali.
L'impatto dell'input al tempo $\mathcal{T}$ sull'output al tempo $t$ esploder\`a esponenzialmente oppure raggiunger\`a rapidamente zero al crescere di $\mathcal{T} - t$, a seconda se il peso $\abs{w_{jj}}>1$ oppure $\abs{w_{jj}}<1$ e anche in base alla funzione di attivazione utilizzata
(ad esempio con data la funzione di attivazione $l_j = \sigma$ si verificher\`a maggiormente il problema della sparizione del gradeinte, viceversa con la funzione ReLU $\operatorname{max}(0, x)$ il gradiente esploder\`a).
